---

title: SmilesPE Tokenizer

keywords: fastai
sidebar: home_sidebar

summary: "Tokenize SMILES (Simplified Molecular-Input Line-Entry System) into substructure units. "
description: "Tokenize SMILES (Simplified Molecular-Input Line-Entry System) into substructure units. "
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: notebooks_build/02_tokenizer.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    {% raw %}
        
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SPE_Tokenizer" class="doc_header"><code>class</code> <code>SPE_Tokenizer</code><a href="" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SPE_Tokenizer</code>(<strong><code>codes</code></strong>, <strong><code>merges</code></strong>=<em><code>-1</code></em>, <strong><code>glossaries</code></strong>=<em><code>None</code></em>, <strong><code>exclusive_tokens</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Tokenize SMILES based on the learned SPE tokens.</p>
<p>codes: output file of <code>learn_SPE()</code></p>
<p>merges: number of learned SPE tokens you want to use. <code>-1</code> means using all of them. <code>1000</code> means use the most frequent 1000.</p>
<p>exclusive_tokens: argument that passes to  <code>atomwise_tokenizer()</code></p>
<p>glossaries: argument that passes to <code>isolate_glossary()</code></p>
<p>dropout: See <a href="https://arxiv.org/abs/1910.13267">BPE-Dropout: Simple and Effective Subword Regularization</a>.
If <code>dropout</code> is set to 0, the segmentation is equivalent to the standard BPE; if <code>dropout</code> is set to 1, the segmentation splits words into distinct characters.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="encode" class="doc_header"><code>encode</code><a href="__main__.py#L78" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>encode</code>(<strong><code>orig</code></strong>, <strong><code>bpe_codes</code></strong>, <strong><code>bpe_codes_reverse</code></strong>, <strong><code>cache</code></strong>, <strong><code>exclusive_tokens</code></strong>=<em><code>None</code></em>, <strong><code>glossaries_regex</code></strong>=<em><code>None</code></em>, <strong><code>dropout</code></strong>=<em><code>0</code></em>)</p>
</blockquote>
<p>Encode word based on list of SPE merge operations, which are applied consecutively.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="isolate_glossary" class="doc_header"><code>isolate_glossary</code><a href="__main__.py#L127" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>isolate_glossary</code>(<strong><code>word</code></strong>, <strong><code>glossary</code></strong>)</p>
</blockquote>
<p>Isolate a glossary present inside a word.</p>
<p>Returns a list of subwords. In which all 'glossary' glossaries are isolated.</p>
<p>For example, if 'USA' is the glossary and '1934USABUSA' the word, the return value is:
    ['1934', 'USA', 'B', 'USA']</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}
</div>
 

