---

title: SMILES Pair Encoding: A Data-Driven Substructure Tokenization Algorithm for Deep Learning

keywords: fastai
sidebar: home_sidebar

summary: "SMILES Pair Encoding (SmilesPE) first learns a vocabulary of high frequency SMILES substrings from a large chemical dataset (e.g., ChEMBL) and then tokenizes SMILES based on the learned vocabulary for deep learning models. SmilesPE is inspired by [byte-pair-encoding (BPE)](https://www.aclweb.org/anthology/P16-1162/)."
description: "SMILES Pair Encoding (SmilesPE) first learns a vocabulary of high frequency SMILES substrings from a large chemical dataset (e.g., ChEMBL) and then tokenizes SMILES based on the learned vocabulary for deep learning models. SmilesPE is inspired by [byte-pair-encoding (BPE)](https://www.aclweb.org/anthology/P16-1162/)."
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: notebooks_build/index.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    {% raw %}
        
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="How-it-works">How it works<a class="anchor-link" href="#How-it-works"> </a></h2><p>A SMILES Pair Encoding (SPE) vocabulary is trained with following steps:</p>
<ul>
<li>Step 1: Tokenize SMILES from a large dataset (e.g., ChEMBL16) at atom-level.</li>
<li>Step 2: Initialize the vocabulary with all unique tokens.</li>
<li>Step 3: Iteratively count the occurs of all token pairs in the tokenized SMILES and merge the most frequent occurring token pair as a new token and add it to the vocabulary. This step will stop when one of the conditions is met: (1) A desired vocabulary size is achieved or (2) No pair of tokens has frequency larger than the frequency threshold. The vocabulary size and frequency threshold are hyperparameters for training SMILES pair encoding. </li>
</ul>
<p>After training the SPE vocabulary, we can then tokenize SMILES based on the trained vocabulary. The SMILES substrings in the trained vocabulary are ordered by their frequency. During the tokenization process, the SMILES is first tokenized at atom-level. SPE will then iteratively check the frequency of each pairs of tokens and merge the pair of tokens that have the highest frequency count in the trained SPE vocabulary until no further merge operation can be conducted.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Installation">Installation<a class="anchor-link" href="#Installation"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">

<pre><code>pip install SmilesPE</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Usage-Instructions">Usage Instructions<a class="anchor-link" href="#Usage-Instructions"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Basic-Tokenizers">Basic Tokenizers<a class="anchor-link" href="#Basic-Tokenizers"> </a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ol>
<li>Atom-level Tokenizer</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">SmilesPE.pretokenizer</span> <span class="kn">import</span> <span class="n">atomwise_tokenizer</span>

<span class="n">smi</span> <span class="o">=</span> <span class="s1">&#39;CC[N+](C)(C)Cc1ccccc1Br&#39;</span>
<span class="n">toks</span> <span class="o">=</span> <span class="n">atomwise_tokenizer</span><span class="p">(</span><span class="n">smi</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">toks</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[&#39;C&#39;, &#39;C&#39;, &#39;[N+]&#39;, &#39;(&#39;, &#39;C&#39;, &#39;)&#39;, &#39;(&#39;, &#39;C&#39;, &#39;)&#39;, &#39;C&#39;, &#39;c&#39;, &#39;1&#39;, &#39;c&#39;, &#39;c&#39;, &#39;c&#39;, &#39;c&#39;, &#39;c&#39;, &#39;1&#39;, &#39;Br&#39;]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ol>
<li>K-mer Tokenzier</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">SmilesPE.pretokenizer</span> <span class="kn">import</span> <span class="n">kmer_tokenizer</span>

<span class="n">smi</span> <span class="o">=</span> <span class="s1">&#39;CC[N+](C)(C)Cc1ccccc1Br&#39;</span>
<span class="n">toks</span> <span class="o">=</span> <span class="n">kmer_tokenizer</span><span class="p">(</span><span class="n">smi</span><span class="p">,</span> <span class="n">ngram</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">toks</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[&#39;CC[N+](&#39;, &#39;C[N+](C&#39;, &#39;[N+](C)&#39;, &#39;(C)(&#39;, &#39;C)(C&#39;, &#39;)(C)&#39;, &#39;(C)C&#39;, &#39;C)Cc&#39;, &#39;)Cc1&#39;, &#39;Cc1c&#39;, &#39;c1cc&#39;, &#39;1ccc&#39;, &#39;cccc&#39;, &#39;cccc&#39;, &#39;ccc1&#39;, &#39;cc1Br&#39;]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The basic tokenizers are also compatible with <a href="https://github.com/aspuru-guzik-group/selfies">SELFIES</a> and <a href="https://github.com/baoilleach/deepsmiles">DeepSMILES</a>. Package installations are required.</p>
<p>Example of SELFIES</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">selfies</span>
<span class="n">smi</span> <span class="o">=</span> <span class="s1">&#39;CC[N+](C)(C)Cc1ccccc1Br&#39;</span>
<span class="n">sel</span> <span class="o">=</span> <span class="n">selfies</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">smi</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;SELFIES string: </span><span class="si">{sel}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="o">&gt;</span> <span class="o">&gt;&gt;</span> <span class="n">SELFIES</span> <span class="n">string</span><span class="p">:</span> <span class="p">[</span><span class="n">C</span><span class="p">][</span><span class="n">C</span><span class="p">][</span><span class="n">N</span><span class="o">+</span><span class="p">][</span><span class="n">Branch1_2</span><span class="p">][</span><span class="n">epsilon</span><span class="p">][</span><span class="n">C</span><span class="p">][</span><span class="n">Branch1_3</span><span class="p">][</span><span class="n">epsilon</span><span class="p">][</span><span class="n">C</span><span class="p">][</span><span class="n">C</span><span class="p">][</span><span class="n">c</span><span class="p">][</span><span class="n">c</span><span class="p">][</span><span class="n">c</span><span class="p">][</span><span class="n">c</span><span class="p">][</span><span class="n">c</span><span class="p">][</span><span class="n">c</span><span class="p">][</span><span class="n">Ring1</span><span class="p">][</span><span class="n">Branch1_1</span><span class="p">][</span><span class="n">Br</span><span class="p">]</span>    
<span class="n">toks</span> <span class="o">=</span> <span class="n">atomwise_tokenizer</span><span class="p">(</span><span class="n">sel</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">toks</span><span class="p">)</span>
<span class="o">&gt;</span> <span class="o">&gt;&gt;</span> <span class="p">[</span><span class="s1">&#39;[C]&#39;</span><span class="p">,</span> <span class="s1">&#39;[C]&#39;</span><span class="p">,</span> <span class="s1">&#39;[N+]&#39;</span><span class="p">,</span> <span class="s1">&#39;[Branch1_2]&#39;</span><span class="p">,</span> <span class="s1">&#39;[epsilon]&#39;</span><span class="p">,</span> <span class="s1">&#39;[C]&#39;</span><span class="p">,</span> <span class="s1">&#39;[Branch1_3]&#39;</span><span class="p">,</span> <span class="s1">&#39;[epsilon]&#39;</span><span class="p">,</span> <span class="s1">&#39;[C]&#39;</span><span class="p">,</span> <span class="s1">&#39;[C]&#39;</span><span class="p">,</span> <span class="s1">&#39;[c]&#39;</span><span class="p">,</span> <span class="s1">&#39;[c]&#39;</span><span class="p">,</span> <span class="s1">&#39;[c]&#39;</span><span class="p">,</span> <span class="s1">&#39;[c]&#39;</span><span class="p">,</span> <span class="s1">&#39;[c]&#39;</span><span class="p">,</span> <span class="s1">&#39;[c]&#39;</span><span class="p">,</span> <span class="s1">&#39;[Ring1]&#39;</span><span class="p">,</span> <span class="s1">&#39;[Branch1_1]&#39;</span><span class="p">,</span> <span class="s1">&#39;[Br]&#39;</span><span class="p">]</span>

<span class="n">toks</span> <span class="o">=</span> <span class="n">kmer_tokenizer</span><span class="p">(</span><span class="n">sel</span><span class="p">,</span> <span class="n">ngram</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">toks</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="p">[</span><span class="s1">&#39;[C][C][N+][Branch1_2]&#39;</span><span class="p">,</span> <span class="s1">&#39;[C][N+][Branch1_2][epsilon]&#39;</span><span class="p">,</span> <span class="s1">&#39;[N+][Branch1_2][epsilon][C]&#39;</span><span class="p">,</span> <span class="s1">&#39;[Branch1_2][epsilon][C][Branch1_3]&#39;</span><span class="p">,</span> <span class="s1">&#39;[epsilon][C][Branch1_3][epsilon]&#39;</span><span class="p">,</span> <span class="s1">&#39;[C][Branch1_3][epsilon][C]&#39;</span><span class="p">,</span> <span class="s1">&#39;[Branch1_3][epsilon][C][C]&#39;</span><span class="p">,</span> <span class="s1">&#39;[epsilon][C][C][c]&#39;</span><span class="p">,</span> <span class="s1">&#39;[C][C][c][c]&#39;</span><span class="p">,</span> <span class="s1">&#39;[C][c][c][c]&#39;</span><span class="p">,</span> <span class="s1">&#39;[c][c][c][c]&#39;</span><span class="p">,</span> <span class="s1">&#39;[c][c][c][c]&#39;</span><span class="p">,</span> <span class="s1">&#39;[c][c][c][c]&#39;</span><span class="p">,</span> <span class="s1">&#39;[c][c][c][Ring1]&#39;</span><span class="p">,</span> <span class="s1">&#39;[c][c][Ring1][Branch1_1]&#39;</span><span class="p">,</span> <span class="s1">&#39;[c][Ring1][Branch1_1][Br]&#39;</span><span class="p">]</span>
</pre></div>
<p>Example of DeepSMILES</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">deepsmiles</span>
<span class="n">converter</span> <span class="o">=</span> <span class="n">deepsmiles</span><span class="o">.</span><span class="n">Converter</span><span class="p">(</span><span class="n">rings</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">branches</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">smi</span> <span class="o">=</span> <span class="s1">&#39;CC[N+](C)(C)Cc1ccccc1Br&#39;</span>
<span class="n">deepsmi</span> <span class="o">=</span> <span class="n">converter</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">smi</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;DeepSMILES string: </span><span class="si">{deepsmi}</span><span class="s1">&#39;</span><span class="p">)</span><span class="o">&gt;</span> <span class="o">&gt;&gt;</span> <span class="n">DeepSMILES</span> <span class="n">string</span><span class="p">:</span> <span class="n">CC</span><span class="p">[</span><span class="n">N</span><span class="o">+</span><span class="p">]</span><span class="n">C</span><span class="p">)</span><span class="n">C</span><span class="p">)</span><span class="n">Ccccccc6Br</span>
<span class="n">toks</span> <span class="o">=</span> <span class="n">atomwise_tokenizer</span><span class="p">(</span><span class="n">deepsmi</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">toks</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="p">[</span><span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="s1">&#39;[N+]&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="s1">&#39;)&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="s1">&#39;)&#39;</span><span class="p">,</span> <span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;6&#39;</span><span class="p">,</span> <span class="s1">&#39;Br&#39;</span><span class="p">]</span>

<span class="n">toks</span> <span class="o">=</span> <span class="n">kmer_tokenizer</span><span class="p">(</span><span class="n">deepsmi</span><span class="p">,</span> <span class="n">ngram</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">toks</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="p">[</span><span class="s1">&#39;CC[N+]C&#39;</span><span class="p">,</span> <span class="s1">&#39;C[N+]C)&#39;</span><span class="p">,</span> <span class="s1">&#39;[N+]C)C&#39;</span><span class="p">,</span> <span class="s1">&#39;C)C)&#39;</span><span class="p">,</span> <span class="s1">&#39;)C)C&#39;</span><span class="p">,</span> <span class="s1">&#39;C)Cc&#39;</span><span class="p">,</span> <span class="s1">&#39;)Ccc&#39;</span><span class="p">,</span> <span class="s1">&#39;Cccc&#39;</span><span class="p">,</span> <span class="s1">&#39;cccc&#39;</span><span class="p">,</span> <span class="s1">&#39;cccc&#39;</span><span class="p">,</span> <span class="s1">&#39;cccc&#39;</span><span class="p">,</span> <span class="s1">&#39;ccc6&#39;</span><span class="p">,</span> <span class="s1">&#39;cc6Br&#39;</span><span class="p">]</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Use-the-Pre-trained-SmilesPE-Tokenizer">Use the Pre-trained SmilesPE Tokenizer<a class="anchor-link" href="#Use-the-Pre-trained-SmilesPE-Tokenizer"> </a></h3><p>Dowbload <a href="https://github.com/XinhaoLi74/SmilesPE/blob/master/SPE_ChEMBL.txt">'SPE_ChEMBL.txt'</a>.</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">codecs</span>
<span class="kn">from</span> <span class="nn">SmilesPE.tokenizer</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">spe_vob</span><span class="o">=</span> <span class="n">codecs</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;../SPE_ChEMBL.txt&#39;</span><span class="p">)</span>
<span class="n">spe</span> <span class="o">=</span> <span class="n">SPE_Tokenizer</span><span class="p">(</span><span class="n">spe_vob</span><span class="p">)</span>

<span class="n">smi</span> <span class="o">=</span> <span class="s1">&#39;CC[N+](C)(C)Cc1ccccc1Br&#39;</span>
<span class="n">spe</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">smi</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span> <span class="s1">&#39;CC [N+](C) (C)C c1ccccc1 Br&#39;</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Train-a-SmilesPE-Tokenizer-with-a-Custom-Dataset">Train a SmilesPE Tokenizer with a Custom Dataset<a class="anchor-link" href="#Train-a-SmilesPE-Tokenizer-with-a-Custom-Dataset"> </a></h3><p>See <a href="https://github.com/XinhaoLi74/SmilesPE/blob/master/Examples/train_SPE.ipynb">train_SPE.ipynb</a> for an example of training A SPE tokenizer on ChEMBL data.</p>

</div>
</div>
</div>
    {% endraw %}
</div>
 

